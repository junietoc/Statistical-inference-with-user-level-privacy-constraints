{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90be18f4-6df5-4430-aec1-66cfe9b44be9",
   "metadata": {},
   "source": [
    "# Week 2-3: Logistic Regression, Differential Privacy Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd8496b-61a0-4e3e-a12d-3fa8657b7781",
   "metadata": {},
   "source": [
    "\n",
    "We will consider the task of binary classification where we are given labeled data $\\{(x_i , y_i )\\}_{i \\in[n]}$\n",
    "with $x_i \\in \\mathbb{R}^d$ and $y_i \\in {−1, 1}$, and the goal is to learn a classifier $f_\\theta : \\mathbb{R}^d \\rightarrow \\{−1, 1\\}$ parameterized by $\\theta \\in \\mathbb{R}^d$ . Given a new sample $x$, our predicted label would be $\\hat{y} = f_\\theta (x)$. One\n",
    "way to learn such a classifier is by using the logistic model defined using the conditional\n",
    "probabilty\n",
    "\n",
    "\n",
    "$P(y = 1|x, θ) = \\frac{e^{\\theta^T x}}{1+ e^{\\theta^T x}}$\n",
    "\n",
    "a) For the above model, verify that checking P(y = 1|x) > P(y = −1|x) is equivalent\n",
    "to checking θ >x > 0. Given this, what would be your strategy to estimate the label\n",
    "once you know θ?\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "\n",
    "$$\\begin{align*}\n",
    "P(y = -1|x, θ) &=  1 - P(y = 1|x, θ) \\\\\n",
    "&= 1 -\\frac{e^{\\theta^T x}}{1+ e^{\\theta^T x}} \\\\ \n",
    "&= \\frac{1}{1+ e^{\\theta^T x}}\n",
    "\\end{align*}$$\n",
    "\n",
    "Then \n",
    "$$P(y = 1|x, θ) > P(y = -1|x, θ)$$\n",
    "$$\\frac{e^{\\theta^T x}}{1+ e^{\\theta^T x}} > \\frac{1}{1+ e^{\\theta^T x}}$$\n",
    "$$e^{\\theta^T x} > 1$$\n",
    "$$\\theta^T x >\\ln{1}$$\n",
    "$$\\theta^T x > 0$$\n",
    "\n",
    "\n",
    "This gives us a the intuition that for given sample $x$ we might assign a label $y=1$ if $\\theta^T x > 0$ and $y=-1$ if $\\theta^T x < 0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59b9411-2cb1-4810-a8c8-09c74e69b9cb",
   "metadata": {},
   "source": [
    "b) Write down the log likelihood function for the above model and describe an algorithm\n",
    "to find the maximum likelihood estimate for θ.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "The maximum likelihood function is\n",
    "$$\\begin{align*}\n",
    "\\mathcal{L}(\\theta) &= \\prod_{y_i} P(y=1 |x,\\theta) \\cdot \\prod_{y_i} (1 - P(y=1 |x,\\theta)) \\\\\n",
    "&= \\prod P(y=1 |x,\\theta)^{y_i} (1 - P(y=1 |x,\\theta))^{(1-y_i)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Finding the log-likelihood, we get:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{l}(\\theta) &= \\sum y_i \\log{P(y=1 |x,\\theta)} + (1-y_i) \\log{1 - P(y=1 |x,\\theta)} \\\\\n",
    "&= \\sum y_i \\log{\\frac{e^{\\theta^T x}}{1+ e^{\\theta^T x}}} + (1-y_i) \\log{\\frac{1}{1+e^{\\theta^T x}}} \\\\ \n",
    "& = \\sum y_i [\\log{\\frac{e^{\\theta^T x}}{1+e^{\\theta^T x}}} - \\log{\\frac{1}{1+e^{\\theta^T x}}}] + \\log{\\frac{1}{1+e^{\\theta^T x}}} \\\\\n",
    "&= \\sum y_i [\\log{(e^{\\theta^T x})} - \\log{(1+e^{\\theta^T x})} + \\log{(1+e^{\\theta^T x}}] + \\log{\\frac{1}{1+e^{\\theta^T x}}} \\\\\n",
    "&= \\sum y_i \\log{(e^{\\theta^T x})} - \\log{(1+e^{\\theta^T x})} \\\\ \n",
    "&= \\sum y_i \\theta^T x - \\log{(1+e^{\\theta^T x})} \n",
    "\\end{align*}$$\n",
    "For maximizing the log-likelihood function we take the derivative and find a zero:\n",
    "$$\\begin{align*}\n",
    "\\nabla_{\\theta} \\mathcal{l}(\\theta) &= \\nabla_{\\theta}[\\sum y_i \\theta^T x - \\log{(1+e^{\\theta^T x})}] \\\\ \n",
    "&= \\sum y_i x_i - \\frac{ e^{\\theta^T x}}{1+e^{\\theta^T x}} x_i \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We can find a root using a newton raphson method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545d7947-0c8b-4a84-a6e6-ffbd8e8baf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "94c99704-c66f-4f5c-a46d-8aa252ef3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(theta, X, y):\n",
    "    \n",
    "    \n",
    "    linear_combination = np.dot(X, theta)\n",
    "    \n",
    "    \n",
    "    log_ll = np.sum(y * linear_combination - np.log(1 + np.exp(linear_combination)))\n",
    "    \n",
    "    return log_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0686c27d-a230-466f-8dd6-312db5893387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood_derivative(theta, X, y):\n",
    "    \n",
    "    linear_combination = np.dot(X, theta)\n",
    "\n",
    "    probabilities = 1 / (1 + np.exp(-linear_combination))\n",
    "    \n",
    "    derivative = np.dot(X, y - probabilities)\n",
    "\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "34a1d594-1beb-42fc-9106-044d94fabab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "d = 50\n",
    "X = np.random.normal(loc=0, scale=np.sqrt(0.1), size=(d))\n",
    "\n",
    "theta_star = np.random.rand(d)\n",
    "\n",
    "linear_combination = X.dot(theta_star)\n",
    "\n",
    "probabilities = 1 / (1 + np.exp(-linear_combination))\n",
    "\n",
    "y = np.array((np.where(probabilities >= 0.5, 1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f9e3e209-b629-42ee-a4e5-1c781e11f05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.21976832e-01, 4.23757145e-01, 9.75226835e-01, 9.64227763e-01,\n",
       "       1.30489622e-01, 7.28939573e-01, 4.70736645e-01, 9.34978389e-01,\n",
       "       7.42560143e-01, 7.21370679e-02, 7.01804745e-01, 8.51162958e-02,\n",
       "       4.85854510e-01, 8.61446580e-01, 4.80594813e-01, 8.60402519e-01,\n",
       "       1.70401160e-01, 8.41748787e-02, 2.93764765e-01, 9.51097056e-01,\n",
       "       3.82254151e-01, 7.48721538e-02, 3.16105800e-01, 4.28513587e-01,\n",
       "       6.64364639e-01, 4.95115432e-01, 4.44202765e-01, 1.60771795e-01,\n",
       "       6.19324042e-01, 5.02171786e-01, 4.91717277e-01, 7.23189401e-01,\n",
       "       2.76368204e-01, 7.53938236e-01, 8.99719038e-01, 3.12210528e-01,\n",
       "       6.59394038e-01, 3.58514879e-01, 1.23134678e-01, 9.90829113e-02,\n",
       "       1.31259072e-01, 1.61318974e-01, 2.90815208e-01, 5.17993698e-01,\n",
       "       8.12507734e-02, 4.54659952e-05, 6.81215874e-02, 5.06304393e-01,\n",
       "       5.45531048e-01, 7.87865690e-01])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "138b5d96-c88c-456e-bfce-f66fbc037a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_raphson(f, J, X, y, theta, tol=1e-6, max_iter=1000):\n",
    "    p0 = theta\n",
    "    p = np.array(p0, dtype=float)\n",
    "    for _ in range(max_iter):\n",
    "        f_val = f(theta, X, y)\n",
    "        if np.linalg.norm(f_val) < tol:\n",
    "            return p\n",
    "        J_val = J(theta, X, y)\n",
    "        p -= f_val / J_val\n",
    "        #print(p)\n",
    "    raise ValueError(\"Newton-Raphson method did not converge within the maximum number of iterations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4c3ddda8-5f6e-436e-99ab-f2a56787accc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Newton-Raphson method did not converge within the maximum number of iterations.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[173], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m theta_initial_guess \u001b[38;5;241m=\u001b[39m theta_star\n\u001b[0;32m----> 3\u001b[0m theta_mle \u001b[38;5;241m=\u001b[39m \u001b[43mnewton_raphson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_likelihood\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_likelihood_derivative\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_initial_guess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m theta_mle\n",
      "Cell \u001b[0;32mIn[172], line 11\u001b[0m, in \u001b[0;36mnewton_raphson\u001b[0;34m(f, J, X, y, theta, tol, max_iter)\u001b[0m\n\u001b[1;32m      9\u001b[0m     p \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m f_val \u001b[38;5;241m/\u001b[39m J_val\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#print(p)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNewton-Raphson method did not converge within the maximum number of iterations.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Newton-Raphson method did not converge within the maximum number of iterations."
     ]
    }
   ],
   "source": [
    "\n",
    "theta_initial_guess = theta_star\n",
    "\n",
    "theta_mle = newton_raphson(log_likelihood, log_likelihood_derivative, X, y, theta_initial_guess)\n",
    "theta_mle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167da2e9-7e50-4ac1-8864-8af1044ac198",
   "metadata": {},
   "source": [
    "## 2. Differential Privacy Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57563ae9-f50d-43ad-8de1-de656dbab696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
